var documenterSearchIndex = {"docs":
[{"location":"usage/#Usage-1","page":"Usage","title":"Usage","text":"","category":"section"},{"location":"usage/#","page":"Usage","title":"Usage","text":"Let's say you have a long-running calculation, organized into batches:","category":"page"},{"location":"usage/#","page":"Usage","title":"Usage","text":"function runbatches()\n    for batch = 1:1000\n        hotloop(batch)\n        # Log progress, etc.\n    end\nend","category":"page"},{"location":"usage/#","page":"Usage","title":"Usage","text":"The hot loop calls the function f(i) which itself calls the type-unstable function get_some_x(i) and  passes the result of it to a calculation calc_with_x.","category":"page"},{"location":"usage/#","page":"Usage","title":"Usage","text":"function hotloop(batch)\n    for i = 1:1_000_000\n        f(i + batch * 1_000_000)\n    end\nend\n\nfunction f(i)\n    x = get_some_x(i)\n    calc_with_x(x)\nend\n\nconst xs = Any[1, 2.0, ComplexF64(3.0, 3.0)]\nget_some_x(i) = xs[i % length(xs) + 1]\ncalc_with_x(x) = x + 42","category":"page"},{"location":"usage/#","page":"Usage","title":"Usage","text":"As get_some_x is not type-stable, calc_with_x must be dynamically dispatched, which slows down the calculation:","category":"page"},{"location":"usage/#","page":"Usage","title":"Usage","text":"julia> @code_warntype f(1)\nVariables\n  #self#::Core.Const(f)\n  i::Int64\n  x::Any\n\nBody::Any\n1 ─      (x = Main.get_some_x(i))\n│   %2 = Main.calc_with_x(x)::Any\n└──      return %2\n\njulia> using BenchmarkTools\n\njulia> @btime hotloop(batch) setup=(batch=rand(1:1000))\n  22.224 ms (666666 allocations: 15.26 MiB)","category":"page"},{"location":"usage/#","page":"Usage","title":"Usage","text":"Catwalk.jl provides the @jit macro that you can use to mark the call site to speed up:","category":"page"},{"location":"usage/#","page":"Usage","title":"Usage","text":"using Catwalk\n\n@jit calc_with_x x function f_jit(i, jitctx) # We create a new function for comparison\n    x = get_some_x(i)\n    calc_with_x(x)\nend","category":"page"},{"location":"usage/#","page":"Usage","title":"Usage","text":"You have to provide the name of the dynamically dispatched function and the argument to operate on to the macro (the API will hopefully improve in the future). You also have to add an extra argument named jitctx to the jit-ed function. So the jit-ed version of the hot loop is:","category":"page"},{"location":"usage/#","page":"Usage","title":"Usage","text":"function hotloop_jit(jitctx)\n    for i = 1:1_000_000\n        f_jit(i, jitctx)\n    end\nend","category":"page"},{"location":"usage/#","page":"Usage","title":"Usage","text":"The Catwalk optimizer will provide you the jitctx context which you have to pass to the jit-ed function manually. Also, every batch needs a bit more housekeeping to drive the Catwalk optimizer:","category":"page"},{"location":"usage/#","page":"Usage","title":"Usage","text":"function runbatches_jit()\n    opt = Catwalk.RuntimeOptimizer()\n    for batch = 1:1000\n        Catwalk.step!(opt)\n        jitctx = Catwalk.ctx(opt)\n        hotloop_jit(jitctx)\n    end\nend","category":"page"},{"location":"usage/#","page":"Usage","title":"Usage","text":"Yes, it is a bit complicated to integrate your code with Catwalk, but it may worth the effort:","category":"page"},{"location":"usage/#","page":"Usage","title":"Usage","text":"julia> @time runbatches_jit()\n 11.652952 seconds (668.95 M allocations: 15.037 GiB, 5.64% gc time, 8.13% compilation time)\n\njulia> @time runbatches()\n 23.684320 seconds (666.67 M allocations: 14.901 GiB, 2.66% gc time)","category":"page"},{"location":"usage/#","page":"Usage","title":"Usage","text":"Please note that the speedup depends on the portion of the runtime spent in dynamic dispatch, which is most likely smaller in your case than in this contrived example.","category":"page"},{"location":"#Catwalk.jl-Intro-1","page":"Catwalk.jl Intro","title":"Catwalk.jl Intro","text":"","category":"section"},{"location":"#","page":"Catwalk.jl Intro","title":"Catwalk.jl Intro","text":"Catwalk.jl can speed up long-running Julia processes by minimizing the overhead of dynamic dispatch.","category":"page"},{"location":"#","page":"Catwalk.jl Intro","title":"Catwalk.jl Intro","text":"It profiles user-specified call sites, estimating the distribution of dynamically dispatched types during runtime, and generates fast static routes for the most frequent ones on the fly.","category":"page"},{"location":"#","page":"Catwalk.jl Intro","title":"Catwalk.jl Intro","text":"The statistical profiler has very low overhead and can be configured to handle situations where the distribution of dispatched types changes relatively fast.","category":"page"},{"location":"#","page":"Catwalk.jl Intro","title":"Catwalk.jl Intro","text":"To minimize compilation overhead, recompilation only occurs when the distribution changed enough so that the  included cost model predicts significant speedup compared to the best version that was previously compiled.","category":"page"},{"location":"#When-to-use-this-package-1","page":"Catwalk.jl Intro","title":"When to use this package","text":"","category":"section"},{"location":"#","page":"Catwalk.jl Intro","title":"Catwalk.jl Intro","text":"The dynamic dispatch in Julia is very fast in itself, so speeding it up is not an easy task. Catwalk.jl focuses on use cases when it is not feasible to list the dynamically dispatched concrete types in the source code of the call site.","category":"page"},{"location":"#","page":"Catwalk.jl Intro","title":"Catwalk.jl Intro","text":"Catwalk.jl assumes the followings:","category":"page"},{"location":"#","page":"Catwalk.jl Intro","title":"Catwalk.jl Intro","text":"The process is long running: at least 6 seconds, but possibly much more is needed to break even after the initial compilation overhead.\nFew dynamically dispatched call sites contribute significantly to the running time (dynamic dispatch in a hot loop).\nYou can modify the source code around the interesting call sites (add a macro call), and calculation is organized into batches.","category":"page"},{"location":"#Alternatives-1","page":"Catwalk.jl Intro","title":"Alternatives","text":"","category":"section"},{"location":"#","page":"Catwalk.jl Intro","title":"Catwalk.jl Intro","text":"ManualDispatch.jl can serve you better in less dynamic cases, when it is feasible to list the dynamically dispatched types in the source code.\nIn even simpler cases using unions instead of a type hierarchy may allow the Julia compiler to \"split the union\". See for example List performance improvent by Union-typed tail in DataStructures.jl.","category":"page"}]
}
